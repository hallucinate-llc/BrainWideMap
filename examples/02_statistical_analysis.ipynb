{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Wide Map: Statistical Analysis Example\n",
    "\n",
    "This notebook demonstrates advanced statistical analysis of Brain Wide Map data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from brainwidemap import DataLoader, Explorer, Statistics, Visualizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "loader = DataLoader(mode='auto')\n",
    "explorer = Explorer(loader)\n",
    "stats = Statistics()\n",
    "viz = Visualizer()\n",
    "\n",
    "# Get a session\n",
    "sessions = explorer.list_sessions(n_trials_min=400)\n",
    "eid = sessions.iloc[0]['eid']\n",
    "\n",
    "# Load data\n",
    "spikes, clusters = loader.load_spike_data(eid)\n",
    "trials = loader.load_trials(eid)\n",
    "\n",
    "print(f\"Session: {eid}\")\n",
    "print(f\"Units: {len(clusters)}\")\n",
    "print(f\"Trials: {len(trials)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trial-Aligned Analysis (PSTH)\n",
    "\n",
    "Compute peri-stimulus time histograms aligned to trial events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get stimulus onset times from trials\n",
    "if 'stimOn_times' in trials.columns:\n",
    "    event_times = trials['stimOn_times'].values\n",
    "    event_times = event_times[~np.isnan(event_times)]\n",
    "    \n",
    "    # Compute PSTH for first few units\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, cluster_id in enumerate(clusters.index[:4]):\n",
    "        time_bins, psth = stats.compute_psth(\n",
    "            spikes['times'],\n",
    "            spikes['clusters'],\n",
    "            cluster_id=cluster_id,\n",
    "            event_times=event_times,\n",
    "            window=(-0.5, 1.0),\n",
    "            bin_size=0.02\n",
    "        )\n",
    "        \n",
    "        axes[i].plot(time_bins, psth)\n",
    "        axes[i].axvline(x=0, color='r', linestyle='--', alpha=0.5)\n",
    "        axes[i].set_xlabel('Time from stimulus (s)')\n",
    "        axes[i].set_ylabel('Firing rate (Hz)')\n",
    "        axes[i].set_title(f'Unit {cluster_id}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No stimulus onset times available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Population Analysis by Brain Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get brain regions\n",
    "regions = loader.get_brain_regions(eid)\n",
    "\n",
    "if len(regions) > 0:\n",
    "    # Compute population statistics for each region\n",
    "    region_stats_list = []\n",
    "    \n",
    "    for region in regions[:10]:  # Top 10 regions\n",
    "        try:\n",
    "            pop_stats = stats.compute_population_statistics(\n",
    "                spikes, clusters, brain_region=region\n",
    "            )\n",
    "            pop_stats['region'] = region\n",
    "            region_stats_list.append(pop_stats)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # Create DataFrame\n",
    "    region_stats_df = pd.DataFrame(region_stats_list)\n",
    "    \n",
    "    # Plot\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Plot 1: Mean firing rate by region\n",
    "    region_stats_df.plot.bar(\n",
    "        x='region', y='mean_firing_rate', \n",
    "        ax=ax1, legend=False, color='steelblue'\n",
    "    )\n",
    "    ax1.set_xlabel('Brain Region')\n",
    "    ax1.set_ylabel('Mean Firing Rate (Hz)')\n",
    "    ax1.set_title('Average Firing Rate by Region')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Number of units by region\n",
    "    region_stats_df.plot.bar(\n",
    "        x='region', y='n_units',\n",
    "        ax=ax2, legend=False, color='coral'\n",
    "    )\n",
    "    ax2.set_xlabel('Brain Region')\n",
    "    ax2.set_ylabel('Number of Units')\n",
    "    ax2.set_title('Unit Count by Region')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nRegion Statistics:\")\n",
    "    print(region_stats_df[['region', 'n_units', 'mean_firing_rate', 'mean_cv']].to_string(index=False))\n",
    "else:\n",
    "    print(\"No brain region information available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trial-by-Trial Variability Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trial-by-trial variability (Fano factor)\n",
    "if 'stimOn_times' in trials.columns and 'feedback_times' in trials.columns:\n",
    "    # Create trial windows\n",
    "    trial_windows = list(zip(\n",
    "        trials['stimOn_times'].values,\n",
    "        trials['feedback_times'].values\n",
    "    ))\n",
    "    \n",
    "    # Remove NaN windows\n",
    "    trial_windows = [(s, e) for s, e in trial_windows if not (np.isnan(s) or np.isnan(e))]\n",
    "    \n",
    "    if len(trial_windows) > 0:\n",
    "        # Compute trial rates and Fano factors for multiple units\n",
    "        fano_factors = []\n",
    "        mean_rates = []\n",
    "        \n",
    "        for cluster_id in clusters.index[:50]:  # First 50 units\n",
    "            trial_rates = stats.compute_trial_firing_rates(\n",
    "                spikes['times'],\n",
    "                spikes['clusters'],\n",
    "                cluster_id=cluster_id,\n",
    "                trial_windows=trial_windows\n",
    "            )\n",
    "            \n",
    "            # Compute spike counts for Fano factor\n",
    "            spike_counts = trial_rates * np.array([e - s for s, e in trial_windows])\n",
    "            fano = stats.compute_fano_factor(spike_counts)\n",
    "            \n",
    "            if not np.isnan(fano):\n",
    "                fano_factors.append(fano)\n",
    "                mean_rates.append(trial_rates.mean())\n",
    "        \n",
    "        # Plot Fano factor vs mean rate\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        ax.scatter(mean_rates, fano_factors, alpha=0.6)\n",
    "        ax.set_xlabel('Mean Firing Rate (Hz)')\n",
    "        ax.set_ylabel('Fano Factor')\n",
    "        ax.set_title('Trial-to-Trial Variability vs Firing Rate')\n",
    "        ax.axhline(y=1, color='r', linestyle='--', alpha=0.5, label='Poisson')\n",
    "        ax.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nMean Fano Factor: {np.mean(fano_factors):.3f}\")\n",
    "        print(f\"Median Fano Factor: {np.median(fano_factors):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation between units\n",
    "# Bin spike times and create firing rate matrix\n",
    "\n",
    "bin_size = 0.1  # 100ms bins\n",
    "t_start = spikes['times'].min()\n",
    "t_end = spikes['times'].max()\n",
    "time_bins = np.arange(t_start, t_end, bin_size)\n",
    "\n",
    "# Use subset of units\n",
    "n_units = min(20, len(clusters))\n",
    "selected_units = clusters.index[:n_units]\n",
    "\n",
    "# Create firing rate matrix\n",
    "fr_matrix = np.zeros((n_units, len(time_bins) - 1))\n",
    "\n",
    "for i, cluster_id in enumerate(selected_units):\n",
    "    cluster_spikes = spikes['times'][spikes['clusters'] == cluster_id]\n",
    "    counts, _ = np.histogram(cluster_spikes, bins=time_bins)\n",
    "    fr_matrix[i, :] = counts / bin_size\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = stats.compute_correlation_matrix(fr_matrix)\n",
    "\n",
    "# Plot\n",
    "fig = viz.plot_correlation_matrix(\n",
    "    corr_matrix,\n",
    "    labels=[f'U{i}' for i in range(n_units)]\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "off_diag = corr_matrix[~np.eye(n_units, dtype=bool)]\n",
    "print(f\"\\nMean pairwise correlation: {off_diag.mean():.3f}\")\n",
    "print(f\"Std pairwise correlation: {off_diag.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Behavioral Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze neural activity in relation to behavioral performance\n",
    "if 'feedbackType' in trials.columns and len(trial_windows) > 0:\n",
    "    # Select a unit\n",
    "    cluster_id = clusters.index[0]\n",
    "    \n",
    "    # Compute trial rates\n",
    "    trial_rates = stats.compute_trial_firing_rates(\n",
    "        spikes['times'],\n",
    "        spikes['clusters'],\n",
    "        cluster_id=cluster_id,\n",
    "        trial_windows=trial_windows[:len(trials)]\n",
    "    )\n",
    "    \n",
    "    # Split by correct/incorrect\n",
    "    correct_mask = trials['feedbackType'].values[:len(trial_rates)] == 1\n",
    "    correct_rates = trial_rates[correct_mask]\n",
    "    incorrect_rates = trial_rates[~correct_mask]\n",
    "    \n",
    "    # Statistical test\n",
    "    if len(correct_rates) > 0 and len(incorrect_rates) > 0:\n",
    "        t_stat, p_val = stats.perform_ttest(correct_rates, incorrect_rates)\n",
    "        \n",
    "        # Plot\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        \n",
    "        positions = [1, 2]\n",
    "        data = [correct_rates, incorrect_rates]\n",
    "        labels = ['Correct', 'Incorrect']\n",
    "        \n",
    "        bp = ax.boxplot(data, positions=positions, labels=labels)\n",
    "        ax.set_ylabel('Firing Rate (Hz)')\n",
    "        ax.set_title(f'Unit {cluster_id}: Activity by Trial Outcome\\n'\n",
    "                    f't={t_stat:.3f}, p={p_val:.4f}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nCorrect trials: mean={correct_rates.mean():.2f}, std={correct_rates.std():.2f}\")\n",
    "        print(f\"Incorrect trials: mean={incorrect_rates.mean():.2f}, std={incorrect_rates.std():.2f}\")\n",
    "        print(f\"t-test: t={t_stat:.3f}, p={p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- PSTH analysis aligned to task events\n",
    "- Population statistics by brain region\n",
    "- Trial-to-trial variability (Fano factor)\n",
    "- Neural correlation analysis\n",
    "- Behavioral correlation of neural activity\n",
    "\n",
    "These analyses provide insights into neural coding and decision-making in the Brain Wide Map dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
